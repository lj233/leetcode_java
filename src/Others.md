# 网络
网络 7 层架构

        7 层模型主要包括：
        1. 物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率
        等。它的主要作用是传输比特流（就是由 1、0 转化为电流强弱来进行传输,到达目的地后在转化为
        也就是我们常说的模数转换与数模转换）。这一层的数据叫做比特。
        2. 数据链路层：主要将从物理层接收的数据进行 MAC 地址（网卡的地址）的封装与解封装。常把这
        一层的数据叫做帧。在这一层工作的设备是交换机，数据通过交换机来传输。
        3. 网络层：主要将从下层接收到的数据进行 IP 地址（例 192.168.0.1)的封装与解封装。在这一层工
        作的设备是路由器，常把这一层的数据叫做数据包。
        4. 传输层：定义了一些传输数据的协议和端口号（WWW 端口 80 等），如：TCP（传输控制协议，
        传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，
        与 TCP 特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如 QQ 聊天数据就是通过这
        种方式传输的）。 主要是将从下层接收的数据进行分段进行传输，到达目的地址后在进行重组。
        常常把这一层数据叫做段。
        5. 会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路。主要在你的系统之间
        发起会话或或者接受会话请求（设备之间需要互相认识可以是 IP 也可以是 MAC 或者是主机名）
        6. 表示层：主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等（也就是把计算机能够
        识别的东西转换成人能够能识别的东西（如图片、声音等））
        7. 应用层 主要是一些终端的应用，比如说FTP（各种文件下载），WEB（IE浏览），QQ之类的（你
        就把它理解成我们在电脑屏幕上可以看到的东西．就 是终端应用）。


TCP/IP 由四个层次组成：网络接口层、网络层、传输层、应用层。

创建TCP谅解，发送http/ 2.0请求

```
Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记
URG：紧急指针（urgent pointer）有效。
ACK：确认序号有效。
PSH：接收方应该尽快将这个报文交给应用层。
RST：重置连接。
SYN：发起一个新连接。
FIN：释放一个连接
```

三次握手

    第一次握手：主机 A 发送位码为 syn＝1,随机产生 seq number=1234567 的数据包到服务器，主机 B
    由 SYN=1 知道，A 要求建立联机；
    第二次握手：主机 B 收到请求后要确认联机信息，向 A 发 送 ack number=( 主 机 A 的
    seq+1),syn=1,ack=1,随机产生 seq=7654321 的包
    第三次握手：主机 A 收到后检查 ack number 是否正确，即第一次发送的 seq number+1,以及位码
    ack 是否为 1，若正确，主机 A 会再发送 ack number=(主机 B 的 seq+1),ack=1，主机 B 收到后确认
    13/04/2018 Page 163 of 283
    seq 值与 ack=1 则连接建立成功。


四次挥手

    TCP 建立连接要进行三次握手，而断开连接要进行四次。这是由于 TCP 的半关闭造成的。因为 TCP 连
    接是全双工的(即数据可在两个方向上同时传递)所以进行关闭时每个方向上都要单独进行关闭。这个单
    方向的关闭就叫半关闭。当一方完成它的数据发送任务，就发送一个 FIN 来向另一方通告将要终止这个
    方向的连接。
    1） 关闭客户端到服务器的连接：首先客户端 A 发送一个 FIN，用来关闭客户到服务器的数据传送，
    然后等待服务器的确认。其中终止标志位 FIN=1，序列号 seq=u
    2） 服务器收到这个 FIN，它发回一个 ACK，确认号 ack 为收到的序号加 1。
     3） 关闭服务器到客户端的连接：也是发送一个 FIN 给客户端。
    4） 客户段收到 FIN 后，并发回一个 ACK 报文确认，并将确认序号 seq 设置为收到序号加 1。
     首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。
     
http状态

    消息响应
    100 Continue(继续)
    101 Switching Protocol(切换协议)
    成功响应
    200 OK(成功)
    201 Created(已创建)
    202 Accepted(已创建)
    203 Non-Authoritative Information(未授权信息)
    204 No Content(无内容)
    205 Reset Content(重置内容)
    206 Partial Content(部分内容)
    重定向
    300 Multiple Choice(多种选择)
    301 Moved Permanently(永久移动)
    302 Found(临时移动)
    303 See Other(查看其他位置)
    304 Not Modified(未修改)
    305 Use Proxy(使用代理)
    306 unused(未使用)
    307 Temporary Redirect(临时重定向)
    308 Permanent Redirect(永久重定向)
    客户端错误
    400 Bad Request(错误请求)
    401 Unauthorized(未授权)
    402 Payment Required(需要付款)
    403 Forbidden(禁止访问)
    404 Not Found(未找到)
    405 Method Not Allowed(不允许使用该方法)
    406 Not Acceptable(无法接受)
    407 Proxy Authentication Required(要求代理身份验证)
    408 Request Timeout(请求超时)
    409 Conflict(冲突)
    410 Gone(已失效)
    411 Length Required(需要内容长度头)
    412 Precondition Failed(预处理失败)
    413 Request Entity Too Large(请求实体过长)
    414 Request-URI Too Long(请求网址过长)
    415 Unsupported Media Type(媒体类型不支持)
    416 Requested Range Not Satisfiable(请求范围不合要求)
    417 Expectation Failed(预期结果失败)
    服务器端错误
    500 Internal Server Error(内部服务器错误)
    501 Implemented(未实现)
    502 Bad Gateway(网关错误)
    503 Service Unavailable(服务不可用)
    504 Gateway Timeout (网关超时)
    505 HTTP Version Not Supported(HTTP 版本不受支持)
    
## Zookeeper 概念
 
     Zookeeper 是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。
     Zookeeper 提供了一个类似于 Linux 文件系统的树形结构（可认为是轻量级的内存文件系统，但
     只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与
     通知机制。
  二、选举流程简述
  
  目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
  
      服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking(选举状态)。
      服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
      服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟。
      服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为小弟。
      服务器5启动，后面的逻辑同服务器4成为小弟
     
## Kafka 概念

    Kafka 是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由 LinkedIn 公司开发，使用
    Scala 语言编写，目前是 Apache 的开源项目。
    1. broker：Kafka 服务器，负责消息存储和转发
    2. topic：消息类别，Kafka 按照 topic 来分类消息
    3. partition：topic 的分区，一个 topic 可以包含多个 partition，topic 消息保存在各个
    partition 上
    4. offset：消息在日志中的位置，可以理解是消息在 partition 上的偏移量，也是代表该消息的
    唯一序号
    5. Producer：消息生产者
    6. Consumer：消息消费者
    7. Consumer Group：消费者分组，每个 Consumer 必须属于一个 group
    8. Zookeeper：保存着集群 broker、topic、partition 等 meta 数据；另外，还负责 broker 故
    障发现，partition leader 选举，负载均衡等功能

## RabbitMQ 概念

    RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。
    AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为
    面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言
    等条件的限制。
    RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可
    用性等方面表现不俗。具体特点包括：
    1. 可靠性（Reliability）：RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布
    确认。
    2. 灵活的路由（Flexible Routing）：在消息进入队列之前，通过 Exchange 来路由消息的。对
    于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路
    由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。
    3. 消息集群（Clustering）：多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。
    4. 高可用（Highly Available Queues）：队列可以在集群中的机器上进行镜像，使得在部分节
    点出问题的情况下队列仍然可用。
    5. 多种协议（Multi-protocol）：RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT
    等等。
    6. 多语言客户端（Many Clients）：RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、
    Ruby 等等。
    7. 管理界面（Management UI）:RabbitMQ 提供了一个易用的用户界面，使得用户可以监控
    和管理消息 Broker 的许多方面。
    8. 跟踪机制（Tracing）:如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生
    了什么。
    9. 插件机制（Plugin System）:RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编
    写自己的插件。
    
    
Hbase 概念

    Hbase 是分布式、面向列的开源数据库（其实准确的说是面向列族）。HDFS 为 Hbase 提供可靠的
    底层数据存储服务，MapReduce 为 Hbase 提供高性能的计算能力，Zookeeper 为 Hbase 提供
    稳定服务和 Failover 机制，因此我们说 Hbase 是一个通过大量廉价的机器解决海量数据的高速存
    储和读取的分布式数据库解决方案
    
    
MongoDB 概念

    MongoDB 是由 C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情
    况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为 WEB 应用提供可扩展的高性能
    数据存储解决方案。
    MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。MongoDB 文档类似
    于 JSON 对象。字段值可以包含其他文档，数组及文档数组。
    
    
# 数据库

    存储引擎主要有： 1. MyIsam 不支持事务 , 2. InnoDB 支持事务和行锁 , 3. Memory 处理速度快，安全性不高, 4. Archive, 5. Federated 。

>MyIASM引擎，B+树的数据结构中存储的内容实际上是实际数据的地址值。也就是说它的索引和实际数据是分开的，只不过使用索引指向了实际数据。这种索引的模式被称为非聚集索引。
 
>    Innodb引擎的索引的数据结构也是B+树，只不过数据结构-》**_叶子节点_** 中存储的都是实际的数据，这种索引有被称为聚集索引。
    
InnoDB（B+树）

    InnoDB 底层存储结构为B+树， B树的每个节点对应innodb的一个page，page大小是固定的，
    一般设为 16k。其中非叶子节点只有键值，叶子节点包含完成数据。
    适用场景：
    1）经常更新的表，适合处理多重并发的更新请求。
    2）支持事务。
    3）可以从灾难中恢复（通过 bin-log 日志等）。
    4）外键约束。只有他支持外键。
    5）支持自动增加列属性 auto_increment。
    
    
第一范式(1st NF －列都是不可再分)（中国北京市-》中国 - 北京市）

    第一范式的目标是确保每列的原子性:如果每列都是不可再分的最小数据单元（也称为最小的原子
    单元），则满足第一范式（1NF）

第二范式(2nd NF－每个表只描述一件事情)
    
    （订单分为订单表和产品表）
    首先满足第一范式，并且表中非主键列不存在对主键的部分依赖。 第二范式要求每个表只描述一
    件事情

第三范式(3rd NF－ 不存在对非主键列的传递依赖)

     第三范式定义是，满足第二范式，并且表中的列不存在对非主键列的传递依赖。除了主键订单编
    号外，顾客姓名依赖于非主键顾客编号。


## 数据库事务

事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作，这些操作作为一个整体一起向

ACID

    系统提交，要么都执行、要么都不执行 。事务是一个不可分割的工作逻辑单元
    事务必须具备以下四个属性，简称 ACID 属性：
    原子性（Atomicity）
    1. 事务是一个完整的操作。事务的各步操作是不可分的（原子的）；要么都执行，要么都不执
    行。
    一致性（Consistency）
    2. 当事务完成时，数据必须处于一致状态。
    隔离性（Isolation）
    3. 对数据进行修改的所有并发事务是彼此隔离的，这表明事务必须是独立的，它不应以任何方
    式依赖于或影响其他事务。
    永久性（Durability）
    4. 事务完成后，它对数据库的修改被永久保持，事务日志能够保持事务的永久性

## 数据库并发策略

    并发控制一般采用三种方法，分别是乐观锁和悲观锁以及时间戳。
  乐观锁
  
    乐观锁认为一个用户读数据的时候，别人不会去写自己所读的数据；悲观锁就刚好相反，觉得自
    己读数据库的时候，别人可能刚好在写自己刚读的数据，其实就是持一种比较保守的态度；时间
    戳就是不加锁，通过时间戳来控制并发出现的问题。
 悲观锁
 
    悲观锁就是在读取数据的时候，为了不让别人修改自己读取的数据，就会先对自己读取的数据加
    锁，只有自己把数据读完了，才允许别人修改那部分数据，或者反过来说，就是自己修改某条数
    据的时候，不允许别人读取该数据，只有等自己的整个事务提交了，才释放自己加上的锁，才允
    许其他用户访问那部分数据。
 时间戳
 
    时间戳就是在数据库表中单独加一列时间戳，比如“TimeStamp”，每次读出来的时候，把该字
    段也读出来，当写回去的时候，把该字段加1，提交之前 ，跟数据库的该字段比较一次，如果比数
    据库的值大的话，就允许保存，否则不允许保存，这种处理方法虽然不使用数据库系统提供的锁
    机制，但是这种方法可以大大提高数据库处理的并发量，
    以上悲观锁所说的加“锁”，其实分为几种锁，分别是：排它锁（写锁）和共享锁（读锁）。


## 数据库锁

共享锁（S）： SELECT*FROM table_name WHERE...LOCK IN SHARE MODE。

排他锁（X)： SELECT*FROM table_name WHERE...FOR UPDATE

> 对于 UPDATE、DELETE、INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)

> MyISAM在执行查询语句 SELECT前，会自动给涉及的所有表加读锁，在执行更新操作（ UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预

19.1.8.1. 行级锁(Innodb)  *InnoDB* 根据索引完成行级锁

行级锁是一种排他锁，防止其他事务修改此行；在使用以下语句时，Oracle 会自动应用行级锁：

    1. INSERT、UPDATE、DELETE、SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];
    2. SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新
    3. 使用 COMMIT 或 ROLLBACK 语句释放锁。
    4. 当选中某一个行的时候,如果是通过主键id选中的。那么这个时候是行级锁。
       其他的行还是可以直接insert 或者update的。
       如果是通过其他的方式选中行,或者选中的条件不明确包含主键。
       这个时候会锁表。其他的事务对该表的任意一行记录都无法进行插入或者更新操作。只能读取。*

19.1.8.2. 表级锁(Innodb,Mylsam)

    表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分 MySQL 引擎支持。最常使
    用的 MYISAM 与 INNODB 都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁
    （排他锁）。

19.1.8.1. 页级锁
页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级
冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB 支持页级锁


丢失更新：两个事务同时更新一行数据，最后一个事务的更新会覆盖掉第一个事务的更新，从而导致第一个事务更新的数据丢失，这是由于没有加锁造成的；
 

    1. 脏读 ：脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。
     e.g.
            1.Mary的原工资为1000, 财务人员将Mary的工资改为了8000(但未提交事务)
            2.Mary读取自己的工资 ,发现自己的工资变为了8000，欢天喜地！
            3.而财务发现操作有误，回滚了事务,Mary的工资又变为了1000
              像这样,Mary记取的工资数8000是一个脏数据。
    
     
    
    2. 不可重复读 ：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。
        e.g.
        1.在事务1中，Mary 读取了自己的工资为1000,操作并没有完成
        2.在事务2中，这时财务人员修改了Mary的工资为2000,并提交了事务.
        3.在事务1中，Mary 再次读取自己的工资时，工资变为了2000
    
     解决办法：如果只有在修改事务完全提交之后才可以读取数据，则可以避免该问题。
    
     
    
    3. 幻读 : 是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。
       e.g.
       目前工资为1000的员工有10人。
       1.事务1,读取所有工资为1000的员工。
       2.这时事务2向employee表插入了一条员工记录，工资也为1000
       3.事务1再次读取所有工资为1000的员工 共读取到了11条记录，
  
  
  事务隔离级别	                脏读	不可重复读	幻读   描述
  读未提交（read-uncommitted）	是	    是	        是       不会施加任何锁
  >
  不可重复读（read-committed）	否	    是	        是       A查不到B未提交的数据，解决了脏读，B提交后出现不可重复读 
  > *每次读取都是最新的版本*

  可重复读（repeatable-read）	否	    否	        是       使用了MVCC机制，select不更新版本号（历史版本，所以另一个事务新增后，这里查询不到）
  >每次读取都是事务当前的版本

  串行化（serializable）	        否	    否	        否       涉及的所有数据被绑定
  
  mysql默认的事务隔离级别为repeatable-read
  InnoDB  相比  MyISAM  有两大特点，一是支持事务。二是支持行级锁
## MVCC 多版本并发控制器 在RC和RR中生成 ReadView的时间是不同的
        在每一行数据中额外保存两个隐藏的列：当前行创建时的版本号和删除时的版本号
        （可能为空，其实还有一列称为回滚指针，用于事务回滚，不在本文范畴）。
        这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。
        事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。
        
        每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目的
  + DATA_TRX_ID
  
  记录最近更新这条行记录的 事务 ID ，大小为  6  个字节
  
  + DATA_ROLL_PTR
  
  表示指向该行回滚段 （rollback segment） 的指针，大小为  7  个字节， InnoDB  便是通过这个指针找到之前版本的数据。该行记录上所有旧版本，在  undo  中都通过链表的形式组织。
  
  + DB_ROW_ID
  
  行标识（隐藏单调自增  ID ），大小为  6  字节，如果表没有主键， InnoDB  会自动生成一个隐藏主键，因此会出现这个列。另外，每条记录的头信息（ record header ）里都有一个专门的  bit （ deleted_flag ）来表示当前记录是否已经被删除。
## ReadView 
    在  RC  隔离级别下，每个  SELECT  语句开始时，都会重新将当前系统中的所有的活跃事务拷贝到一个列表生成  ReadView 。二者的区别就在于生成  ReadView  的时间点不同，一个是事务之后第一个  SELECT  语句开始、一个是事务中每条  SELECT  语句开始。
    
    ReadView  中是当前活跃的事务  ID  列表，称之为  m_ids ，其中最小值为  up_limit_id ，最大值为  low_limit_id ，事务  ID  是事务开启时  InnoDB  分配的，其大小决定了事务开启的先后顺序，因此我们可以通过  ID  的大小关系来决定版本记录的可见性，具体判断流程如下：
    
    如果被访问版本的  trx_id  小于  m_ids  中的最小值  up_limit_id ，说明生成该版本的事务在  ReadView  生成前就已经提交了，所以该版本可以被当前事务访问。
    
    如果被访问版本的  trx_id  大于  m_ids  列表中的最大值  low_limit_id ，说明生成该版本的事务在生成  ReadView  后才生成，所以该版本不可以被当前事务访问。需要根据  Undo Log  链找到前一个版本，然后根据该版本的 DB_TRX_ID 重新判断可见性。
    
    如果被访问版本的  trx_id  属性值在  m_ids  列表中最大值和最小值之间（包含），那就需要判断一下  trx_id  的值是不是在  m_ids  列表中。如果在，说明创建  ReadView  时生成该版本所属事务还是活跃的，因此该版本不可以被访问，需要查找 Undo Log 链得到上一个版本，然后根据该版本的  DB_TRX_ID  再从头计算一次可见性；如果不在，说明创建  ReadView  时生成该版本的事务已经被提交，该版本可以被访问。
    
    此时经过一系列判断我们已经得到了这条记录相对  ReadView  来说的可见结果。此时，如果这条记录的  delete_flag  为  true ，说明这条记录已被删除，不返回。否则说明此记录可以安全返回给客户端  

## CAP
  
        CAP 原则又称 CAP 定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability
      （可用性）、Partition tolerance（分区容错性），三者不可得兼。
      一致性（C）：
      1. 在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份
      最新的数据副本）
      可用性（A）：
      2. 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备
      高可用性）
      分区容忍性（P）：
      3. 以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，
      就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。
      
## 利用索引
    // 优化前
    
    SELECT id, cu_id, name, info, biz_type
        , gmt_create, gmt_modified, start_time, end_time, market_type
        , back_leaf_category, item_status, picuture_url
    FROM relation
    WHERE biz_type = '0'
        AND end_time >= '2014-05-29'
    ORDER BY id ASC
    LIMIT 149420, 20;
    
    
    // 优化后
    
    SELECT a.*
    FROM relation a, (
            SELECT id
            FROM relation
            WHERE biz_type = '0'
                AND end_time >= '2014-05-29'
            ORDER BY id ASC
            LIMIT 149420, 20
        ) b
    WHERE a.id = b.id
    解释：其实这里就是通过使用覆盖索引查询返回需要的主键,再根据主键关联原表获得需要的数据。这样就是充分利用了索引！
> [优化链接](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247483856&idx=1&sn=ea1c06f0852d3bca3b98b64d8589598e&chksm=ebd740d1dca0c9c77ed1bb07a96bd0fbe147a13515797cf71597de821dbe3357e3eef5f741dc&scene=21###wechat_redirect)
## sql 分组
```sql

-- 利用了分组的去重，同时如果想查出分组之外的属性，也可以这么子查询 
select * from user where id in(
   select min(id) from user where name = 'Java3y' and pv = 20 and time='7-25' group by name,pv,time;
)
```

## join

+ 在join的时候一定要写关联条件，如果是inner join的话，只有符合关联条件的数据才会存在最大表中

+ 如果是left join的话，即便关联条件不符合，左边表的数据一定会存在大表中

+ 如果是right join的话，即便关联条件不符合，右边表的数据一定会存在大表中

## case when
```sql
SELECT C.* , 
    CASE WHEN C.T_NUMBER = '1' THEN '男' 
        WHEN C.T_NUMBER = '2' THEN '女'
        ELSE '其他'
        END AS '性别'
    FROM DAY20190706 C;
```

## Mysql log
+ undo log 回滚和多版本控制(MVCC)
> undo log主要存储的也是逻辑日志，
>比如我们要insert一条数据了，
>那undo log会记录的一条对应的delete日志。我们要update一条记录时，
>它会记录一条对应相反的update记录

+ binlog 记录了数据库表结构和表数据变更,除了select，存储变更的sql和事务id
> 复制和恢复数据
+ redo log 记载着在每个页上做的修改，用来恢复数据 使用Innodb引擎会有
> 实际上Mysql的基本存储结构是页(记录都存在页里边)，
>所以MySQL是先把这条记录所在的页找到，
>然后把该页加载到内存中，将对应记录进行修改。

*Mysql* 需要保证redo log和binlog的一致性，事务也需要两个日志记录都成功才可以

## 表删除
+ 不再需要一张表的时候，用drop
 
+ 想删除部分数据行时候，用delete，并且带上where子句
 
+ 保留表而删除所有数据的时候用truncate

## 索引 页的目录
> 首先Mysql的基本存储结构是页(记录都存在页里边) 各个数据页可以组成一个双向链表，而每个数据页中的记录又可以组成一个单向链表
>所以没有索引：先遍历双向链表在遍历单向链表

### 最左匹配原则：

索引可以简单如一个列 (a)，也可以复杂如多个列 (a,b,c,d)，即联合索引。

如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），遇到范围查询 (>、<、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找。

因此，列的排列顺序决定了可命中索引的列数

### =、in自动优化顺序

不需要考虑=、in等的顺序，mysql会自动优化这些条件的顺序，以匹配尽可能多的索引列。

> 一般来说，在WHERE和JOIN中出现的列需要建立索引，但也不完全如此，

（1）是一种快速查询表中内容的机制，类似于新华字典的目录

（2）运用在表中某个些字段上，但存储时，独立于表之外
+ InnoDB使用的是B+Tree。
>B+Tree：每一个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的范围遍历。
+ 组合索引必须从最左边查 必须从最左边差，不能跳过
+ 不能使用索引中范围条件右边的列，范围查询会导致后面的的索引失效

### InnoDB的聚簇索引：
    InnoDB对主键建立聚簇索引。
    如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。
    如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。
 >聚簇索引：节点页只包含了索引列，叶子页包含了行的全部数据。聚簇索引“就是表”，因此可以不需要独立的行存储

+ 聚集索引在叶子节点存储的是表中的数据

+ 非聚集索引在叶子节点存储的是主键和索引列
### MyISAM建立的索引结构大致如下：

col1主键索引：按照主键大小排序，节点数据为行号。

### explain 解释命令

explain select * from user；

### sql分类
（1）DML（数据操纵语言）：select，insert，update，delete

（2）DDL（数据定义语言）：create table，alter table，drop table，truncate table

（3）DCL（数据控制语言）：grant select any table to scott/revoke select any table from scott

（4）TCL（事务控制语言）：commit，rollback，savepoint to 回滚点